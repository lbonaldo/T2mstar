Training dataset size:  640000
Validation dataset size:  160000
================================================================================
Config options:

  N_blocks                 	6
  adam_betas               	(0.9, 0.95)
  add_pad_noise            	0.0001
  add_y_noise              	0.05
  add_z_noise              	0.05
  batch_norm               	False
  batch_size               	1000
  data_path                	/mnt/scratch/bonal1lCMICH/inverse/spline/data
  device                   	cuda
  dropout_perc             	0.2
  exponent_clamping        	2.0
  filename_in              	
  filename_out             	/mnt/scratch/bonal1lCMICH/inverse/spline/results/Jan-27-2022/12-29-21/inn.pt
  final_decay              	0.01
  hidden_layer_sizes       	128
  init_scale               	0.1
  interactive_visualization	False
  l2_weight_reg            	0.01
  lambd_fit_forw           	0.001
  lambd_max_likelihood     	0.001
  lambd_mmd_back           	10.0
  lambd_mmd_forw           	1.0
  lambd_reconstruct        	1.0
  logfile                  	/mnt/scratch/bonal1lCMICH/inverse/spline/results/Jan-27-2022/12-29-21/out.txt
  lr_init                  	0.01
  mmd_back_kernels         	[(1, 0.1), (1, 0.5), (1, 2)]
  mmd_back_weighted        	True
  mmd_forw_kernels         	[(1, 2), (1, 2), (1, 2)]
  n_epochs                 	60
  n_its_per_epoch          	5000
  ndim_pad_x               	0
  ndim_pad_zy              	0
  ndim_x                   	10
  ndim_y                   	5
  ndim_z                   	5
  pre_low_lr               	0
  test_path                	/mnt/scratch/bonal1lCMICH/inverse/spline/results/Jan-27-2022/12-29-21
  test_time_functions      	[]
  train_backward_mmd       	True
  train_forward_mmd        	True
  train_max_likelihood     	True
  train_reconstruction     	True
  use_cuda                 	True
  use_permutation          	False
  verbose_construction     	False
  y_uncertainty_sigma      	0.1
  zeros_noise_scale        	100
================================================================================

Best loss:  inf
New loss:  53315.97440185547
Model saved.
Epoch             L_ML           L_fit       L_mmd_fwd      L_mmd_back       L_reconst      L_ML(test)     L_fit(test) L_mmd_fwd(test) L_mmd_back(test) L_reconst(test)
                                                                                    000    6636340.4571      26517.3503          0.1812          0.0597  26372638423.3968   13418443.5934      53315.9744          0.1837          0.0599   19118517.0366
Best loss:  53315.97440185547
New loss:  18852.897162914276
Model saved.
                                                                                    001    9617415.7109      38452.4498          0.1833          0.0598  21617845574.7016    4715959.4868      18852.8972          0.1837          0.0600     426719.5305
Best loss:  18852.897162914276
New loss:  77.4541763484478
Model saved.
                                                                                    002    3670402.9056      14676.5310          0.1838          0.0599    4500134.1186      19371.1289         77.4542          0.1838          0.0600      15799.6573
                                                                                    003  543996291.4632    2173294.9831          0.1839          0.0600  90471914500.8646     226185.4682        902.9990          0.1837          0.0600    8249645.2611
Best loss:  77.4541763484478
New loss:  5.078774616867304
Model saved.
                                                                                    004    4990186.3052      19899.1198          0.1836          0.0600    4462585.1047       1271.1155          5.0788          0.1829          0.0600        961.5354
                                                                                    005     574634.3696       2294.1936          0.1836          0.0597   24950467.2393      25619.2791        101.9652          0.1843          0.0597    1891463.9359
Best loss:  5.078774616867304
New loss:  0.9215642955154181
Model saved.
                                                                                    006    2195081.6591       8758.1073          0.1842          0.0595     616683.3146        232.5157          0.9216          0.1839          0.0596         71.7391
Best loss:  0.9215642955154181
New loss:  0.5199087587650866
Model saved.
                                                                                    007   14829233.3629      58887.1915          0.1888          0.0568       5141.3042        133.3598          0.5199          0.1953          0.0567        102.5683
                                                                                    008     100948.6184        401.0820          0.1903          0.0550      10133.4651       7945.9805         31.5654          0.1866          0.0565        400.7731
                                                                                    009    2424716.4485       9636.7067          0.1842          0.0567  117319104.2272       5449.9881         21.6977          0.1843          0.0566        759.4095
                                                                                    010     659320.1211       2625.6863          0.1839          0.0586     359995.3729       4500.6628         17.4353          0.1846          0.0586        191.2415
                                                                                    011    1000290.6619       3974.3545          0.1771          0.0569       9063.3478       6907.7010         26.7902          0.1825          0.0544        307.7746
                                                                                    012    1556846.0757       6194.3888          0.1825          0.0545     353601.8752        505.3685          2.0166          0.1849          0.0542       2083.6758
                                                                                    013     375039.5180       1489.1535          0.1835          0.0537  393648496.5253       5159.5355         20.5277          0.1838          0.0533      10291.2279
                                                                                    014      80237.5852        319.6935          0.1830          0.0539     175888.5185        148.1553          0.5909          0.1838          0.0539        117.7028
                                                                                    015     419545.0273       1674.4538          0.1834          0.0536   20939902.3353      22711.8150         90.1517          0.1841          0.0551   24294889.9433
                                                                                    016     107637.4449        428.9381          0.1829          0.0546     169664.2574        802.1812          3.1503          0.1787          0.0534        459.0285
Best loss:  0.5199087587650866
New loss:  0.011062454909551888
Model saved.
                                                                                    017      63408.6086        250.0771          0.1855          0.0547      47033.9371          2.9312          0.0111          0.1939          0.0562          5.7534
Best loss:  0.011062454909551888
New loss:  0.0018789561712765136
Model saved.
                                                                                    018       5488.2618         21.2511          0.2191          0.0522        549.2726          0.5536          0.0019          0.1847          0.0499         34.0546
Best loss:  0.0018789561712765136
New loss:  0.001203411007008981
Model saved.
                                                                                    019          5.0015          0.0189          0.1457          0.0435          3.4165          0.3485          0.0012          0.0644          0.0393          1.0574
Best loss:  0.001203411007008981
New loss:  0.000819001933632535
Model saved.
                                                                                    020          0.2870          0.0011          0.0552          0.0442          0.5541          0.2164          0.0008          0.0542          0.0487          0.0357
Best loss:  0.000819001933632535
New loss:  0.0008175388298695907
Model saved.
                                                                                    021          0.2145          0.0008          0.0532          0.0486          0.0300          0.2167          0.0008          0.0531          0.0482          0.0279
Best loss:  0.0008175388298695907
New loss:  0.0008145619238348444
Model saved.
                                                                                    022          0.2128          0.0008          0.0528          0.0484          0.0285          0.2137          0.0008          0.0516          0.0485          0.0279
Best loss:  0.0008145619238348444
New loss:  0.0008067261882388266
Model saved.
                                                                                    023          0.2124          0.0008          0.0524          0.0487          0.0287          0.2116          0.0008          0.0524          0.0489          0.0308
                                                                                    024          0.2129          0.0008          0.0524          0.0489          0.0296          0.2131          0.0008          0.0530          0.0490          0.0303
                                                                                    025          0.2128          0.0008          0.0523          0.0490          0.0297          0.2131          0.0008          0.0534          0.0490          0.0298
Best loss:  0.0008067261882388266
New loss:  0.0008055849808442872
Model saved.
                                                                                    026          0.2128          0.0008          0.0521          0.0490          0.0300          0.2085          0.0008          0.0514          0.0491          0.0312
                                                                                    027          0.2130          0.0008          0.0521          0.0490          0.0301          0.2123          0.0008          0.0522          0.0490          0.0315
                                                                                    028          0.2129          0.0008          0.0520          0.0490          0.0301          0.2119          0.0008          0.0523          0.0490          0.0303
                                                                                    029          0.2128          0.0008          0.0521          0.0490          0.0301          0.2139          0.0008          0.0523          0.0490          0.0298
                                                                                    030          0.2123          0.0008          0.0518          0.0490          0.0301          0.2121          0.0008          0.0520          0.0490          0.0320
                                                                                    031          0.2126          0.0008          0.0520          0.0490          0.0300          0.2119          0.0008          0.0513          0.0490          0.0299
                                                                                    032          0.2124          0.0008          0.0520          0.0489          0.0297          0.2125          0.0008          0.0513          0.0490          0.0285
                                                                                    033          0.2121          0.0008          0.0518          0.0490          0.0299          0.2126          0.0008          0.0521          0.0489          0.0293
                                                                                    034          0.2125          0.0008          0.0520          0.0490          0.0300          0.2148          0.0008          0.0523          0.0488          0.0282
                                                                                    035          0.2124          0.0008          0.0519          0.0489          0.0300          0.2124          0.0008          0.0520          0.0489          0.0300
                                                                                    036          0.2123          0.0008          0.0519          0.0489          0.0299          0.2129          0.0008          0.0528          0.0489          0.0291
                                                                                    037          0.2123          0.0008          0.0520          0.0489          0.0297          0.2112          0.0008          0.0514          0.0489          0.0299
                                                                                    038          0.2121          0.0008          0.0518          0.0489          0.0299          0.2128          0.0008          0.0518          0.0489          0.0289
                                                                                    039          0.2123          0.0008          0.0519          0.0489          0.0300          0.2133          0.0008          0.0518          0.0489          0.0292
                                                                                    040          0.2119          0.0008          0.0518          0.0489          0.0298          0.2109          0.0008          0.0513          0.0490          0.0303
                                                                                    041          0.2118          0.0008          0.0517          0.0489          0.0299          0.2135          0.0008          0.0513          0.0489          0.0298
                                                                                    042          0.2121          0.0008          0.0520          0.0489          0.0297          0.2134          0.0008          0.0523          0.0489          0.0294
                                                                                    043          0.2122          0.0008          0.0520          0.0489          0.0295          0.2126          0.0008          0.0526          0.0489          0.0284
                                                                                    044          0.2115          0.0008          0.0518          0.0489          0.0296          0.2124          0.0008          0.0517          0.0489          0.0291
                                                                                    045          0.2120          0.0008          0.0519          0.0489          0.0297          0.2105          0.0008          0.0515          0.0490          0.0295
                                                                                    046          0.2114          0.0008          0.0518          0.0489          0.0297          0.2119          0.0008          0.0517          0.0489          0.0295
                                                                                    047          0.2119          0.0008          0.0519          0.0489          0.0295          0.2120          0.0008          0.0516          0.0489          0.0302
                                                                                    048          0.2119          0.0008          0.0519          0.0489          0.0294          0.2116          0.0008          0.0516          0.0489          0.0289
                                                                                    049          0.2117          0.0008          0.0519          0.0489          0.0295          0.2117          0.0008          0.0517          0.0489          0.0303
                                                                                    050          0.2117          0.0008          0.0518          0.0489          0.0295          0.2112          0.0008          0.0516          0.0489          0.0292
                                                                                    051          0.2115          0.0008          0.0518          0.0489          0.0295          0.2121          0.0008          0.0517          0.0489          0.0292
                                                                                    052          0.2118          0.0008          0.0520          0.0489          0.0294          0.2116          0.0008          0.0519          0.0488          0.0293
                                                                                    053          0.2115          0.0008          0.0518          0.0489          0.0295          0.2114          0.0008          0.0521          0.0489          0.0301
                                                                                    054          0.2118          0.0008          0.0519          0.0489          0.0294          0.2117          0.0008          0.0521          0.0488          0.0293
                                                                                    055          0.2115          0.0008          0.0518          0.0489          0.0294          0.2122          0.0008          0.0519          0.0489          0.0286
                                                                                    056          0.2114          0.0008          0.0518          0.0489          0.0295          0.2119          0.0008          0.0518          0.0489          0.0296
                                                                                    057          0.2115          0.0008          0.0518          0.0489          0.0294          0.2117          0.0008          0.0518          0.0489          0.0291
                                                                                    058          0.2117          0.0008          0.0518          0.0489          0.0294          0.2116          0.0008          0.0515          0.0489          0.0302
                                                                                    059          0.2118          0.0008          0.0519          0.0489          0.0293          0.2121          0.0008          0.0522          0.0488          0.0292


Training took 66.785078 minutes


Test dataset size:  200000
Test results:  0.8062741


Testing took 0.134784 minutes


